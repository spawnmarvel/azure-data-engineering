# azure-data-engineering
Stuff about azure data engineering

## Microsoft Certified: Azure Data Engineer Associate DP-203: Data Engineering on Microsoft Azure

https://learn.microsoft.com/en-us/certifications/azure-data-engineer/


## Practice Assessments for Microsoft Certifications

https://learn.microsoft.com/en-us/certifications/practice-assessments-for-microsoft-certifications#availability

## Study guide

https://learn.microsoft.com/en-us/certifications/resources/study-guides/DP-203


Skills measured
* Design and implement data storage (15–20%)
* Develop data processing (40–45%)
* Secure, monitor, and optimize data storage and data processing (30–35%)

## dp-203-azure-data-engineer/Instructions/Labs/

https://github.com/MicrosoftLearning/dp-203-azure-data-engineer/tree/master/Instructions/Labs

## MS Learn

https://learn.microsoft.com/en-us/certifications/azure-data-engineer/

### Get started with data engineering on Azure

#### What is data engineering

Types of data
* Structured, table based, relation, or flat file csv
* Semi-structured, JSON
* Unstructured, pdf, word and images

Data integration
* Data Integration involves establishing links between operational and analytical services and data sources to enable secure, reliable access to data across multiple systems. 

Data transformation
* Operational data usually needs to be transformed into suitable structure and format for analysis, often as part of an extract, transform, and load (ETL) process; though increasingly a variation in which you extract, load, and transform (ELT)

Data consolidation
* Data consolidation is the process of combining data that has been extracted from multiple data sources into a consistent structure - usually to support analytics and reporting.

Common languages
* SQL, Python, others

### Important data engineering concepts

Operational and analytical data
* Operational data is usually transactional data that is generated and stored by applications, often in a relational or non-relational database. 
* Analytical data is data that has been optimized for analysis and reporting, often in a data warehouse.

Streaming data
* Streaming data refers to perpetual sources of data that generate data values in real-time, often relating to specific events.

Data pipelines
* Data pipelines are used to orchestrate activities that transfer and transform data.

Data lakes
* A data lake is a storage repository that holds large amounts of data in native, raw formats.
* The idea with a data lake is to store everything in its original, untransformed state. This approach differs from a traditional data warehouse, which transforms and processes the data at the time of ingestion.

Data warehouses
* A data warehouse is a centralized repository of integrated data from one or more disparate sources.

Apache Spark
* Apache Spark is a parallel processing framework that takes advantage of in-memory processing and a distributed file storage. It's a common open-source software (OSS) tool for big data scenarios.


### Data engineering in Microsoft Azure

![Data Engineering in Azure ](https://github.com/spawnmarvel/azure-data-engineering/blob/main/images/data-eng-azure.jpg)


### Build data analytics solutions using Azure Synapse serverless SQL pools

### Perform data engineering with Azure Synapse Apache Spark Pools

### Work with Data Warehouses using Azure Synapse Analytics

### Transfer and transform data with Azure Synapse Analytics pipelines

### Work with Hybrid Transactional and Analytical Processing Solutions using Azure Synapse Analytics

### Implement a Data Streaming Solution with Azure Stream Analytics

### Govern data across an enterprise

### Data engineering with Azure Databricks

